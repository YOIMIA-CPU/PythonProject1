"""
AuraVision æ™ºèƒ½è§†é¢‘è¡Œä¸ºè¯†åˆ« - åç«¯APIæœåŠ¡
åç«¯æ¡†æ¶: FastAPI
Pythonç‰ˆæœ¬: 3.8+
ä¾èµ–: pip install fastapi uvicorn python-multipart opencv-python numpy pillow
"""

import os
import json
import time
import asyncio
import threading
from datetime import datetime
from pathlib import Path
from typing import Optional, List, Dict, Any
from uuid import uuid4

import cv2
import numpy as np
from fastapi import FastAPI, UploadFile, File, Form, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from pydantic import BaseModel
import aiofiles
from PIL import Image
import base64
import io

# åˆå§‹åŒ–FastAPIåº”ç”¨
app = FastAPI(
    title="AuraVision API",
    description="æ™ºèƒ½è§†é¢‘è¡Œä¸ºè¯†åˆ«ç³»ç»Ÿåç«¯API",
    version="2.1.4"
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒåº”é™åˆ¶ä¸ºå…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å­˜å‚¨åˆ†æçŠ¶æ€å’Œç»“æœ
analysis_states = {}
video_metadata = {}
connections = {}

# æ•°æ®æ¨¡å‹
class AnalysisRequest(BaseModel):
    video_id: str
    mode: str = "standard"
    config: Optional[Dict[str, Any]] = None

class DetectionResult(BaseModel):
    timestamp: float
    objects: List[Dict[str, Any]]
    behaviors: List[Dict[str, Any]]
    confidence: float
    frame_number: int

class VideoMetadata(BaseModel):
    filename: str
    duration: float
    resolution: Dict[str, int]
    size: int
    fps: float
    codec: str

class SystemStatus(BaseModel):
    status: str
    gpu_usage: float
    memory_usage: float
    cpu_usage: float
    temperature: float
    network_latency: int

# å·¥å…·å‡½æ•°
def generate_id() -> str:
    """ç”Ÿæˆå”¯ä¸€ID"""
    return str(uuid4())

def get_file_size_mb(file_path: str) -> float:
    """è·å–æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰"""
    return os.path.getsize(file_path) / (1024 * 1024)

def extract_video_metadata(video_path: str) -> Dict:
    """æå–è§†é¢‘å…ƒæ•°æ®"""
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        return {}
    
    metadata = {
        "fps": cap.get(cv2.CAP_PROP_FPS),
        "width": int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
        "height": int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),
        "frame_count": int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),
        "codec": "unknown"
    }
    
    metadata["duration"] = metadata["frame_count"] / metadata["fps"] if metadata["fps"] > 0 else 0
    
    cap.release()
    return metadata

async def simulate_analysis(video_id: str, video_path: str):
    """æ¨¡æ‹Ÿè§†é¢‘åˆ†æè¿‡ç¨‹"""
    try:
        # æ¨¡æ‹Ÿå¤„ç†è¿‡ç¨‹
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        analysis_states[video_id]["status"] = "processing"
        analysis_states[video_id]["total_frames"] = total_frames
        analysis_states[video_id]["processed_frames"] = 0
        
        frame_count = 0
        detection_history = []
        
        while cap.isOpened() and analysis_states[video_id]["status"] == "processing":
            ret, frame = cap.read()
            if not ret:
                break
            
            # æ¨¡æ‹Ÿæ£€æµ‹å»¶è¿Ÿ
            await asyncio.sleep(0.01)
            
            # ç”Ÿæˆæ¨¡æ‹Ÿæ£€æµ‹ç»“æœ
            timestamp = frame_count / fps if fps > 0 else 0
            detections = []
            behaviors = []
            
            # éšæœºç”Ÿæˆä¸€äº›æ£€æµ‹ç»“æœç”¨äºæ¼”ç¤º
            if frame_count % 30 == 0:  # æ¯30å¸§æ£€æµ‹ä¸€æ¬¡
                num_objects = np.random.randint(1, 5)
                for i in range(num_objects):
                    detections.append({
                        "id": f"obj_{frame_count}_{i}",
                        "type": np.random.choice(["person", "vehicle", "animal", "object"]),
                        "confidence": np.random.uniform(0.7, 0.99),
                        "bbox": {
                            "x": np.random.randint(0, frame.shape[1] - 100),
                            "y": np.random.randint(0, frame.shape[0] - 100),
                            "width": np.random.randint(50, 200),
                            "height": np.random.randint(50, 200)
                        },
                        "attributes": {}
                    })
                    
                    # éšæœºç”Ÿæˆè¡Œä¸º
                    if np.random.random() > 0.7:
                        behaviors.append({
                            "type": np.random.choice(["walking", "running", "standing", "interacting"]),
                            "confidence": np.random.uniform(0.6, 0.95),
                            "object_id": f"obj_{frame_count}_{i}"
                        })
            
            result = {
                "frame_number": frame_count,
                "timestamp": timestamp,
                "objects": detections,
                "behaviors": behaviors,
                "confidence": np.mean([d["confidence"] for d in detections]) if detections else 0
            }
            
            detection_history.append(result)
            analysis_states[video_id]["results"].append(result)
            analysis_states[video_id]["processed_frames"] = frame_count + 1
            
            # æ›´æ–°è¿›åº¦
            progress = (frame_count + 1) / total_frames
            analysis_states[video_id]["progress"] = progress
            
            # æ¨¡æ‹Ÿå®æ—¶æ•°æ®æ¨é€
            if frame_count % 10 == 0 and video_id in connections:
                await send_realtime_update(video_id, result)
            
            frame_count += 1
            
            # å¯ä»¥æ§åˆ¶å¤„ç†é€Ÿåº¦
            if frame_count >= 1000:  # é™åˆ¶å¤„ç†å¸§æ•°ç”¨äºæ¼”ç¤º
                break
        
        cap.release()
        
        # ç”Ÿæˆæœ€ç»ˆåˆ†æç»“æœ
        analysis_states[video_id]["status"] = "completed"
        analysis_states[video_id]["completion_time"] = datetime.now().isoformat()
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        if detection_history:
            confidences = [r["confidence"] for r in detection_history if r["confidence"] > 0]
            analysis_states[video_id]["statistics"] = {
                "total_detections": len([r for r in detection_history if r["objects"]]),
                "total_behaviors": len([r for r in detection_history if r["behaviors"]]),
                "avg_confidence": np.mean(confidences) if confidences else 0,
                "max_confidence": max(confidences) if confidences else 0,
                "detection_rate": len(detection_history) / (analysis_states[video_id]["duration"] or 1)
            }
        
    except Exception as e:
        analysis_states[video_id]["status"] = "error"
        analysis_states[video_id]["error"] = str(e)
    finally:
        if video_id in connections:
            await send_final_result(video_id)

async def send_realtime_update(video_id: str, data: Dict):
    """å‘é€å®æ—¶æ›´æ–°åˆ°WebSocketè¿æ¥"""
    if video_id in connections:
        for websocket in connections[video_id]:
            try:
                await websocket.send_json({
                    "type": "realtime_update",
                    "data": data,
                    "timestamp": datetime.now().isoformat()
                })
            except:
                pass

async def send_final_result(video_id: str):
    """å‘é€æœ€ç»ˆç»“æœ"""
    if video_id in connections:
        for websocket in connections[video_id]:
            try:
                await websocket.send_json({
                    "type": "analysis_complete",
                    "data": analysis_states[video_id],
                    "timestamp": datetime.now().isoformat()
                })
            except:
                pass

# APIç«¯ç‚¹
@app.post("/api/upload")
async def upload_video(file: UploadFile = File(...)):
    """ä¸Šä¼ è§†é¢‘æ–‡ä»¶"""
    try:
        # ç”Ÿæˆå”¯ä¸€ID
        video_id = generate_id()
        
        # ä¿å­˜æ–‡ä»¶
        upload_dir = Path("uploads")
        upload_dir.mkdir(exist_ok=True)
        
        file_path = upload_dir / f"{video_id}_{file.filename}"
        
        # å¼‚æ­¥ä¿å­˜æ–‡ä»¶
        async with aiofiles.open(file_path, 'wb') as f:
            content = await file.read()
            await f.write(content)
        
        # æå–å…ƒæ•°æ®
        metadata = extract_video_metadata(str(file_path))
        
        # å­˜å‚¨å…ƒæ•°æ®
        video_metadata[video_id] = {
            "id": video_id,
            "filename": file.filename,
            "path": str(file_path),
            "size": get_file_size_mb(str(file_path)),
            "upload_time": datetime.now().isoformat(),
            "metadata": metadata
        }
        
        # åˆå§‹åŒ–åˆ†æçŠ¶æ€
        analysis_states[video_id] = {
            "id": video_id,
            "status": "uploaded",
            "progress": 0,
            "results": [],
            "start_time": None,
            "completion_time": None,
            "duration": metadata.get("duration", 0),
            "total_frames": metadata.get("frame_count", 0),
            "processed_frames": 0
        }
        
        return {
            "success": True,
            "video_id": video_id,
            "metadata": video_metadata[video_id],
            "message": "è§†é¢‘ä¸Šä¼ æˆåŠŸ"
        }
        
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"success": False, "error": str(e)}
        )

@app.post("/api/analyze")
async def analyze_video(request: AnalysisRequest):
    """å¼€å§‹åˆ†æè§†é¢‘"""
    try:
        video_id = request.video_id
        
        if video_id not in analysis_states:
            return JSONResponse(
                status_code=404,
                content={"success": False, "error": "è§†é¢‘ä¸å­˜åœ¨"}
            )
        
        if analysis_states[video_id]["status"] in ["processing", "completed"]:
            return JSONResponse(
                status_code=400,
                content={"success": False, "error": "è§†é¢‘å·²åœ¨åˆ†æä¸­æˆ–å·²å®Œæˆåˆ†æ"}
            )
        
        # è·å–è§†é¢‘è·¯å¾„
        video_path = video_metadata[video_id]["path"]
        
        # æ›´æ–°çŠ¶æ€
        analysis_states[video_id].update({
            "status": "processing",
            "start_time": datetime.now().isoformat(),
            "mode": request.mode,
            "config": request.config or {}
        })
        
        # å¼‚æ­¥å¯åŠ¨åˆ†æä»»åŠ¡
        asyncio.create_task(simulate_analysis(video_id, video_path))
        
        return {
            "success": True,
            "message": "åˆ†æä»»åŠ¡å·²å¯åŠ¨",
            "analysis_id": video_id,
            "status": analysis_states[video_id]["status"]
        }
        
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"success": False, "error": str(e)}
        )

@app.get("/api/status/{video_id}")
async def get_analysis_status(video_id: str):
    """è·å–åˆ†æçŠ¶æ€"""
    if video_id not in analysis_states:
        return JSONResponse(
            status_code=404,
            content={"success": False, "error": "è§†é¢‘ä¸å­˜åœ¨"}
        )
    
    status = analysis_states[video_id]
    
    # è®¡ç®—å®æ—¶æŒ‡æ ‡
    detection_count = len([r for r in status["results"] if r["objects"]])
    behavior_count = len([r for r in status["results"] if r["behaviors"]])
    confidence_scores = [r["confidence"] for r in status["results"] if r["confidence"] > 0]
    avg_confidence = np.mean(confidence_scores) if confidence_scores else 0
    
    response = {
        "success": True,
        "status": status["status"],
        "progress": status["progress"],
        "video_metadata": video_metadata.get(video_id, {}),
        "statistics": {
            "detection_count": detection_count,
            "behavior_count": behavior_count,
            "confidence_score": f"{avg_confidence:.1%}",
            "processed_frames": status["processed_frames"],
            "total_frames": status["total_frames"],
            "processing_fps": status["processed_frames"] / (time.time() - datetime.fromisoformat(status["start_time"]).timestamp()) if status["start_time"] else 0
        },
        "real_time_data": {
            "current_detections": status["results"][-1]["objects"] if status["results"] else [],
            "current_behaviors": status["results"][-1]["behaviors"] if status["results"] else [],
            "timestamp": status["results"][-1]["timestamp"] if status["results"] else 0
        }
    }
    
    return response

@app.get("/api/results/{video_id}")
async def get_analysis_results(video_id: str, limit: int = 100, offset: int = 0):
    """è·å–åˆ†æç»“æœ"""
    if video_id not in analysis_states:
        return JSONResponse(
            status_code=404,
            content={"success": False, "error": "è§†é¢‘ä¸å­˜åœ¨"}
        )
    
    status = analysis_states[video_id]
    results = status["results"][offset:offset + limit]
    
    # æ ¼å¼åŒ–ç»“æœ
    formatted_results = []
    for result in results:
        formatted_results.append({
            "timestamp": result["timestamp"],
            "timecode": f"{int(result['timestamp'] // 3600):02d}:{int((result['timestamp'] % 3600) // 60):02d}:{int(result['timestamp'] % 60):02d}.{int((result['timestamp'] * 1000) % 1000):03d}",
            "objects": len(result["objects"]),
            "behaviors": [b["type"] for b in result["behaviors"]],
            "confidence": f"{result['confidence']:.1%}",
            "frame_number": result["frame_number"]
        })
    
    return {
        "success": True,
        "total_results": len(status["results"]),
        "showing": len(formatted_results),
        "offset": offset,
        "limit": limit,
        "results": formatted_results,
        "summary": status.get("statistics", {})
    }

@app.get("/api/system/status")
async def get_system_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    # æ¨¡æ‹Ÿç³»ç»ŸçŠ¶æ€ï¼ˆå®é™…é¡¹ç›®ä¸­åº”è·å–çœŸå®ç³»ç»Ÿä¿¡æ¯ï¼‰
    import psutil
    import GPUtil
    
    gpus = GPUtil.getGPUs() if hasattr(GPUtil, 'getGPUs') else []
    gpu_usage = gpus[0].load * 100 if gpus else 0
    
    return {
        "success": True,
        "system_status": {
            "status": "online",
            "gpu_usage": round(gpu_usage, 1),
            "memory_usage": round(psutil.virtual_memory().percent, 1),
            "cpu_usage": round(psutil.cpu_percent(), 1),
            "temperature": 55.5,  # æ¨¡æ‹Ÿæ¸©åº¦
            "network_latency": 12,
            "storage_usage": 48.0,  # 2.4TB / 5TB
            "power_consumption": 348
        },
        "engine_status": {
            "model_status": "running",
            "inference_engine": "TensorRT",
            "precision": "FP16",
            "version": "2.1.4"
        }
    }

@app.get("/api/export/{video_id}")
async def export_results(video_id: str, format: str = "json"):
    """å¯¼å‡ºåˆ†æç»“æœ"""
    if video_id not in analysis_states:
        return JSONResponse(
            status_code=404,
            content={"success": False, "error": "è§†é¢‘ä¸å­˜åœ¨"}
        )
    
    status = analysis_states[video_id]
    
    if format == "json":
        return {
            "success": True,
            "video_id": video_id,
            "metadata": video_metadata.get(video_id, {}),
            "analysis_config": {
                "mode": status.get("mode", "standard"),
                "config": status.get("config", {})
            },
            "statistics": status.get("statistics", {}),
            "results": status["results"][-100:],  # è¿”å›æœ€å100å¸§ç»“æœ
            "timeline": [
                {
                    "timestamp": r["timestamp"],
                    "detection_count": len(r["objects"]),
                    "behavior_count": len(r["behaviors"]),
                    "avg_confidence": r["confidence"]
                }
                for r in status["results"][::30]  # æ¯30å¸§é‡‡æ ·
            ]
        }
    
    return JSONResponse(
        status_code=400,
        content={"success": False, "error": f"ä¸æ”¯æŒçš„æ ¼å¼: {format}"}
    )

@app.post("/api/control")
async def control_analysis(action: str = Form(...), video_id: Optional[str] = Form(None)):
    """æ§åˆ¶åˆ†æè¿‡ç¨‹"""
    if action == "pause" and video_id in analysis_states:
        analysis_states[video_id]["status"] = "paused"
        return {"success": True, "message": "åˆ†æå·²æš‚åœ"}
    
    elif action == "resume" and video_id in analysis_states:
        analysis_states[video_id]["status"] = "processing"
        return {"success": True, "message": "åˆ†æå·²æ¢å¤"}
    
    elif action == "stop" and video_id in analysis_states:
        analysis_states[video_id]["status"] = "stopped"
        return {"success": True, "message": "åˆ†æå·²åœæ­¢"}
    
    elif action == "restart" and video_id in analysis_states:
        analysis_states[video_id].update({
            "status": "processing",
            "results": [],
            "processed_frames": 0,
            "progress": 0
        })
        return {"success": True, "message": "åˆ†æå·²é‡å¯"}
    
    return JSONResponse(
        status_code=400,
        content={"success": False, "error": "æ— æ•ˆçš„æ“ä½œæˆ–è§†é¢‘ID"}
    )

@app.websocket("/ws/realtime/{video_id}")
async def websocket_realtime(websocket: WebSocket, video_id: str):
    """WebSocketå®æ—¶æ•°æ®æ¨é€"""
    await websocket.accept()
    
    if video_id not in connections:
        connections[video_id] = []
    connections[video_id].append(websocket)
    
    try:
        while True:
            # ä¿æŒè¿æ¥æ´»è·ƒ
            await websocket.receive_text()
            
    except WebSocketDisconnect:
        connections[video_id].remove(websocket)
        if not connections[video_id]:
            del connections[video_id]

@app.get("/api/frame/{video_id}/{frame_number}")
async def get_frame_preview(video_id: str, frame_number: int):
    """è·å–è§†é¢‘å¸§é¢„è§ˆ"""
    if video_id not in video_metadata:
        return JSONResponse(
            status_code=404,
            content={"success": False, "error": "è§†é¢‘ä¸å­˜åœ¨"}
        )
    
    video_path = video_metadata[video_id]["path"]
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        return JSONResponse(
            status_code=500,
            content={"success": False, "error": "æ— æ³•æ‰“å¼€è§†é¢‘"}
        )
    
    # è·³è½¬åˆ°æŒ‡å®šå¸§
    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
    ret, frame = cap.read()
    cap.release()
    
    if not ret:
        return JSONResponse(
            status_code=404,
            content={"success": False, "error": "å¸§ä¸å­˜åœ¨"}
        )
    
    # è½¬æ¢ä¸ºbase64
    _, buffer = cv2.imencode('.jpg', frame)
    frame_base64 = base64.b64encode(buffer).decode('utf-8')
    
    return {
        "success": True,
        "frame_number": frame_number,
        "timestamp": frame_number / 30,  # å‡è®¾30fps
        "image": f"data:image/jpeg;base64,{frame_base64}"
    }

@app.get("/api/heatmap/{video_id}")
async def get_heatmap_data(video_id: str):
    """è·å–çƒ­åŠ›å›¾æ•°æ®"""
    if video_id not in analysis_states:
        return JSONResponse(
            status_code=404,
            content={"success": False, "error": "è§†é¢‘ä¸å­˜åœ¨"}
        )
    
    # ç”Ÿæˆæ¨¡æ‹Ÿçƒ­åŠ›å›¾æ•°æ®
    heatmap_data = []
    for i in range(100):
        heatmap_data.append({
            "x": np.random.uniform(0, 1),
            "y": np.random.uniform(0, 1),
            "value": np.random.uniform(0, 1)
        })
    
    return {
        "success": True,
        "heatmap": heatmap_data
    }

# å¯åŠ¨è„šæœ¬
if __name__ == "__main__":
    import uvicorn
    
    # åˆ›å»ºå¿…è¦ç›®å½•
    Path("uploads").mkdir(exist_ok=True)
    Path("results").mkdir(exist_ok=True)
    
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                           â•‘
    â•‘    AuraVision API Server å¯åŠ¨ä¸­...                       â•‘
    â•‘    ğŸš€ AI è§†é¢‘è¡Œä¸ºè¯†åˆ«ç³»ç»Ÿ                                â•‘
    â•‘    ğŸ“¡ ç›‘å¬: http://localhost:8000                        â•‘
    â•‘    ğŸ“š APIæ–‡æ¡£: http://localhost:8000/docs                â•‘
    â•‘                                                           â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    uvicorn.run(app, host="0.0.0.0", port=8000)